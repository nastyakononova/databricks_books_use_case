{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "157da292-156f-4c29-9019-c5a551356614",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5463c72-979f-4124-92e7-049f60bbe2c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog_name = \"dev_silver\"\n",
    "schema_name = \"books\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01b3e840-566a-4305-bd9b-320bb8496d06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Import of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cd69f06-e91e-47d7-9cd6-c2558a599617",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, DateType\n",
    "from pyspark.sql.functions import col, count, when, isnan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8a7bb44-bd38-416d-8e18-88e2eb9d7d48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Books silver table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "590cb638-0c12-4fd2-aa76-c0467bbed607",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38492dab-1c0d-42ab-8362-3106a6152891",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"=== BASIC DATASET INFORMATION ===\")\n",
    "\n",
    "books =  spark.table(\"dev_bronze.books.books_bronze\")\n",
    "\n",
    "# Dataset Shape (rows, columns)\n",
    "row_count = books.count()\n",
    "col_count = len(books.columns)\n",
    "print(f\"Dataset shape: ({row_count}, {col_count})\")\n",
    "\n",
    "# Column Names\n",
    "print(f\"\\n=== Column names ===\\n{books.columns}\")\n",
    "\n",
    "# Data Types\n",
    "print(\"\\n=== Data types ===\")\n",
    "books.printSchema()\n",
    "\n",
    "# Missing Values Count per Column\n",
    "print(\"\\n=== Missing values ===\")\n",
    "missing_counts = books.select([\n",
    "    count(when(col(c).isNull(), c)).alias(c) for c in books.columns\n",
    "])\n",
    "missing_counts.show()\n",
    "\n",
    "# Duplicate Rows Count\n",
    "print(\"\\n=== Duplicate rows ===\")\n",
    "duplicates_count = row_count - books.dropDuplicates().count()\n",
    "print(f\"Duplicate rows: {duplicates_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39dded73-35ec-4fd0-822f-af61a004b4c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Creation of books silver table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6cbb034-49fe-4e63-ae2a-4447cdbcfe90",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"Publisher\":148},\"columnVisibility\":{}},\"settings\":{\"columns\":{\"Image_URL_S\":{\"format\":{\"preset\":\"string-preset-url\"}},\"Image_URL_M\":{\"format\":{\"preset\":\"string-preset-url\"}},\"Image_URL_L\":{\"format\":{\"preset\":\"string-preset-url\"}}}},\"syncTimestamp\":1752568649169}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "table_name = \"books_silver\"\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ISBN\", StringType(), True),\n",
    "    StructField(\"Book_Title\", StringType(), True),\n",
    "    StructField(\"Book_Author\", StringType(), True),\n",
    "    StructField(\"Year_Of_Publication\", StringType(), True),\n",
    "    StructField(\"Publisher\", StringType(), True),\n",
    "    StructField(\"Image_URL_S\", StringType(), True),\n",
    "    StructField(\"Image_URL_M\", StringType(), True),\n",
    "    StructField(\"Image_URL_L\", StringType(), True),\n",
    "    StructField(\"Current_Timestamp\", DateType(), True)\n",
    "])\n",
    "\n",
    "df = spark.sql(f\"\"\"\n",
    "    select \n",
    "        distinct ISBN,\n",
    "        coalesce(trim(`Book-Title`), \"Unknown\") as Book_Title,\n",
    "        coalesce(trim(INITCAP(REGEXP_REPLACE(`Book-Author`, r'\\s*\\.\\s*', '. '))), \"Unknown\") as Book_Author,\n",
    "        CASE\n",
    "            WHEN try_cast(`Year-Of-Publication` AS INT) IS NULL THEN 'Unknown'\n",
    "            WHEN try_cast(`Year-Of-Publication` AS INT) > year(current_date()) THEN 'Unknown'\n",
    "            WHEN try_cast(`Year-Of-Publication` AS INT) < 1000 THEN 'Unknown'\n",
    "            ELSE cast(`Year-Of-Publication` AS STRING)\n",
    "        END AS Year_Of_Publication,\n",
    "        coalesce(trim(`Publisher`), \"Unknown\") as Publisher,\n",
    "        coalesce(trim(`Image-URL-S`), \"Unknown\") as Image_URL_S,\n",
    "        coalesce(trim(`Image-URL-M`), \"Unknown\") as Image_URL_M,\n",
    "        coalesce(trim(`Image-URL-L`), \"Unknown\") as Image_URL_L,\n",
    "        cast(current_timestamp() as date) as Current_Timestamp\n",
    "    from dev_bronze.books.books_bronze  \n",
    "    where ISBN is not null\n",
    "\"\"\")\n",
    "display(df)\n",
    "\n",
    "(df.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(f\"{catalog_name}.{schema_name}.{table_name}\")\n",
    ")\n",
    "print(f\"Table {table_name} updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf0fb74e-13f3-4082-b0cd-b327df4a471e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Ratings silver table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c300c436-8499-4370-ac5f-630ab7310301",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2a3b3f0-ed8a-460c-a6f5-f3a880664403",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"=== BASIC DATASET INFORMATION ===\")\n",
    "\n",
    "ratings =  spark.table(\"dev_bronze.books.ratings_bronze\")\n",
    "\n",
    "# Dataset Shape (rows, columns)\n",
    "row_count = ratings.count()\n",
    "col_count = len(ratings.columns)\n",
    "print(f\"Dataset shape: ({row_count}, {col_count})\")\n",
    "\n",
    "# Column Names\n",
    "print(f\"\\n=== Column names ===\\n{ratings.columns}\")\n",
    "\n",
    "# Data Types\n",
    "print(\"\\n=== Data types ===\")\n",
    "ratings.printSchema()\n",
    "\n",
    "# Missing Values Count per Column\n",
    "print(\"\\n=== Missing values ===\")\n",
    "missing_counts = ratings.select([\n",
    "    count(when(col(c).isNull(), c)).alias(c) for c in ratings.columns\n",
    "])\n",
    "missing_counts.show()\n",
    "\n",
    "# Duplicate Rows Count\n",
    "print(\"\\n=== Duplicate rows ===\")\n",
    "duplicates_count = row_count - ratings.dropDuplicates().count()\n",
    "print(f\"Duplicate rows: {duplicates_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c0bbea6-45d9-49e8-b1b1-4b00433761f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Creation of ratings silver table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "978cc558-eff0-4aa2-b92e-b7bd9bbaadee",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1752571607291}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "table_name = \"ratings_silver\"\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"User_ID\", IntegerType(), True),\n",
    "    StructField(\"ISBN\", IntegerType(), True),\n",
    "    StructField(\"Book_Rating\", IntegerType(), True),\n",
    "    StructField(\"Current_Timestamp\", DateType(), True)\n",
    "])\n",
    "\n",
    "df = spark.sql(f\"\"\"\n",
    "    select \n",
    "        ISBN,\n",
    "        cast(coalesce(`User-ID`, 999999999) as int) as User_ID,\n",
    "        cast(`Book-Rating` as int) as Book_Rating,\n",
    "        cast(current_timestamp() as date) as Current_Timestamp\n",
    "    from dev_bronze.books.ratings_bronze  \n",
    "    where ISBN is not null \n",
    "        and `Book-Rating` is not null\n",
    "        and `Book-Rating` between 0 and 10\n",
    "    group by \n",
    "        ISBN,\n",
    "        `User-ID`,\n",
    "        `Book-Rating`\n",
    "\n",
    "\"\"\")\n",
    "display(df)\n",
    "\n",
    "(df.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(f\"{catalog_name}.{schema_name}.{table_name}\")\n",
    ")\n",
    "print(f\"Table {table_name} updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9565829a-a4e9-4d29-b286-213f845bf475",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Users silver table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8faa7d44-c217-4f4e-9659-dac7347ebe62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffb7fa57-9386-4d87-9d7f-4f335fd564ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"=== BASIC DATASET INFORMATION ===\")\n",
    "\n",
    "users =  spark.table(\"dev_bronze.books.users_bronze\")\n",
    "\n",
    "# Dataset Shape (rows, columns)\n",
    "row_count = users.count()\n",
    "col_count = len(users.columns)\n",
    "print(f\"Dataset shape: ({row_count}, {col_count})\")\n",
    "\n",
    "# Column Names\n",
    "print(f\"\\n=== Column names ===\\n{users.columns}\")\n",
    "\n",
    "# Data Types\n",
    "print(\"\\n=== Data types ===\")\n",
    "users.printSchema()\n",
    "\n",
    "# Missing Values Count per Column\n",
    "print(\"\\n=== Missing values ===\")\n",
    "missing_counts = users.select([\n",
    "    count(when(col(c).isNull(), c)).alias(c) for c in users.columns\n",
    "])\n",
    "missing_counts.show()\n",
    "\n",
    "# Duplicate Rows Count\n",
    "print(\"\\n=== Duplicate rows ===\")\n",
    "duplicates_count = row_count - users.dropDuplicates().count()\n",
    "print(f\"Duplicate rows: {duplicates_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b52d93b-2abc-418c-9e2d-1a9bb36f0b9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Creation of ratings silver table\n",
    "The column `Location` is not cleaned and split. Cleaning and spliting will be done in further development of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50e9373b-f63f-41df-88d8-086df1bee69c",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1752573173770}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "table_name = \"users_silver\"\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"User_ID\", IntegerType(), True),\n",
    "    StructField(\"Location\", StringType(), True),\n",
    "    StructField(\"Age\", IntegerType(), True),\n",
    "    StructField(\"Current_Timestamp\", DateType(), True)\n",
    "])\n",
    "\n",
    "df = spark.sql(f\"\"\"\n",
    "    select \n",
    "        cast(`User-ID` as int) as User_ID,\n",
    "        Location,\n",
    "        CASE\n",
    "            WHEN try_cast(`Age` AS decimal) IS NULL THEN 'Unknown'\n",
    "            WHEN try_cast(`Age` AS decimal) < 5 THEN 'Unknown'\n",
    "            WHEN try_cast(`Age` AS decimal) > 120 THEN 'Unknown'\n",
    "            ELSE cast(`Age` AS STRING)\n",
    "        end as Age,\n",
    "        cast(current_timestamp() as date) as Current_Timestamp\n",
    "    from dev_bronze.books.users_bronze  \n",
    "    where `User-ID` is not null \n",
    "    group by\n",
    "        `User-ID`,\n",
    "        `Location`,\n",
    "        `Age`\n",
    "\n",
    "\"\"\")\n",
    "display(df)\n",
    "\n",
    "(df.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(f\"{catalog_name}.{schema_name}.{table_name}\")\n",
    ")\n",
    "print(f\"Table {table_name} updated\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7354187898364125,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "transformations_silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
